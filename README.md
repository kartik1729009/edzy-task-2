ğŸ•·ï¸ Sitemap Crawler â€“ Edzy.ai
This project is a backend crawler service for analyzing the link structure of Edzy.ai (or any website with a sitemap).
It crawls pages from a sitemap, extracts outgoing links, classifies them as internal or external, and identifies incoming links for each page. It also summarizes the most linked-to pages across the site.
ğŸ“Œ Features
âœ… Crawl all pages listed in a sitemap
âœ… Extract outgoing links from each page
âœ… Classify links as internal or external
âœ… Identify incoming links for each page
âœ… Find top N most linked pages
âœ… Store crawl data (HTML, links, metadata) in MongoDB
âœ… REST API endpoints to query linking information
âš™ï¸ Tech Stack
Node.js + Express â†’ API backend
MongoDB + Mongoose â†’ Data storage
Axios â†’ Fetch HTML content
Cheerio â†’ Parse and extract links from HTML
Bruno â†’ API testing (alternative to Postman)
ğŸš€ Installation
Clone the repository:
git clone <your-repo-url>
cd backend
Install dependencies:
npm install
Create a .env file:
PORT=3000
MONGO_URI=mongodb://localhost:27017/edzycrawler
SITEMAP_URL=https://www.edzy.ai/sitemap.xml
Start the server:
tsc -b
node dist/index.js

Server will run at:
ğŸ‘‰ http://localhost:3000
